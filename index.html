<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Diseño de métodos de cuantificación aplicados a la estimación de la distribución de grupos taxonómicos presentes en muestras de plancton</title>
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/simple.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
		<style>
			.container{
				display: flex;
			}
			blockquote{
				background-color:#F0F0F0;
				padding:15px;
				font-weight: 285;
			}

			.col{
				flex: 1;
			}
			.reveal section p,section ul{
    font-size: 0.9em !important;

}
.MathJax span{
font-size: xx-large;
}

figcaption {
	font-size:0.8em !important;
}

ul {list-style-type: square;}

ul{
	text-align: left;
	line-height: 1.4;
}

.resaltar
{
	color:rgba(0,129,195,.9);
}

li{
	margin: 0 0 15px 0;
}

.reveal p, .reveal ul {
    line-height: 1.35;
	font-weight:350 !important;
}

.reveal section pre code {
    font-size: 0.7em !important;
}
		</style>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">

				<section>
					<h3>Diseño de métodos de cuantificación aplicados a la estimación de la distribución de grupos taxonómicos presentes en muestras de plancton</h3>
					<hr/>
					<div style="margin-top:50px">
						<div style="float:left;text-align:center">
						<p><small><spam class="resaltar">Autor </spam><br/>Pablo González González</small><br></p>
						</div>
						<div style="float:right">
						<p>
						<small><spam class="resaltar">Directores </spam><br/>Dr. Juan José Del Coz<br/>Dr. Jorge Díez</small></p>
					</div></div>


<div>
<img style="width:20%" src="img/uniovi.jpg"/>

</div>
<p style="text-align:center">
<small>Doctorado en Informática, Universidad de Oviedo, 2019</small>
</p>
				</section>

				<section>
					<h2>Introducción</h2>
					<p>Desarrollo de técnicas y métodos adecuados para cuantificar muestras de plancton descritas a partir de imágenes capturadas por dispositivos automáticos</p>
					<img style="width:100%" src="img/plankton_images.png"</img>
				</section>

				<section>
					<h3>¿En qué consiste cuantificar?</h3>
					<p>El objetivo es procesar una muestra de plancton y obtener la distribución de los organismos existentes en ella</p>
					<img src="img/cuantificar.png" style="padding:10px;background-color:white;width:100%" ></img>
					<aside class="notes">
						<ul>
							<li>Diferencia entre cuantificación y clasificación</li>
							<li>Particularidades del problema (cambio de distribución)</li>
					 </ul>
					</aside>
				</section>

				<section>
					<h2>Fases del proceso</h2>
					<p>Para poder construir un modelo de cuantificación, tendremos que completar las siguientes fases</p>
					<img src="img/visiongeneral.png" style="width:90%" ></img>
					<aside class="notes">
						<ul>
							<li>Particularidades del problema (cambio de distribución)</li>
					 </ul>
					</aside>
				</section>

				<section>
					<h2>Fase 1</h2>
					<h3>Obtención de muestras</h3>
				</section>

				<section>
					<h3>Conjuntos de datos utilizados</h3>
					<ul>
						<li>Conjunto de datos del Instituto Oceanográfico de Gijón</li>
						<li>Conjunto de datos del Woods Hole Oceanographic Institution</li>
					</ul>
					<div style="float:left;width:40%;margin-left:5%">
							<img src="img/gijon.jpg"></img>
					</div>
					<div style="float:left;width:40%">
							<img src="img/woods.png" ></img>
					</div>
				</section>

				<section>
					<h4>Conjunto de datos del Instituto Oceanográfico de Gijón</h4>
					<div class="container">
						<div class="col">
							<ul>
								<li>Muestras obtenidas en <spam class="resaltar">diferentes localizaciones</spam> del Mar Cantábrico</li>
								<li>Formado por <spam class="resaltar">60 muestras</spam> y unas <spam class="resaltar">40.000 imágenes</spam> etiquetadas manualmente en <spam class="resaltar">8 categorías</spam></li>
							</ul>
						</div>
						<div class="col">
							<img src="img/distribucioniog.png" style="width:75%;padding:10px"/>
						</div>
					</div>
					<aside class="notes">
						<ul>
							<li>Utiliza la flowcam que puede ir en un barco</li>
							<li>Diversidad espacial y temporal que garantiza una gran variabilidad en los datos</li>
					 </ul>
					</aside>
				</section>

				<section>
					<h4>Conjunto de datos del Woods Hole Oceanographic Institution</h4>
						<p>Formado por <span class="resaltar">964 muestras</span> y <span class="resaltar">3.4 millones de imágenes</span> etiquetadas manualmente en <span class="resaltar">50 categorías</span></p>
						<img src="img/mvco.jpg" style="width:50%"/>
						<aside class="notes">
							<ul>
								<li>Martha Vineyard Coastal Observatory (Martha Vineyard island, Massachussets)</li>
							 	<li>FlowCytobot situada a 4 metros de profundidad. Cable marino hasta el observatorio.</li>
								<li>Serie temporal desde 2006</li>
						 </ul>
						</aside>
				</section>

				<section>
					<h3>Dispositivos de captura utilizados para obtener las imágenes</h3>
					<div style="float:left;width:30%;margin-left:15%;margin-right:10%;margin-top:10%">
<figure>
							<img src="img/flowcam.jpg" style="width:100%"></img>
							<figcaption>Flowcam (Utilizado por el IEO)</figcaption>
						</figure>
					</div>

					<div style="float:left;width:30%">
						<figure>
							<img src="img/flowcytobot.jpg" style="width:100%" ></img>
							<figcaption>FlowCytobot (Utilizado por el WHOI)</figcaption>
						</figure>
					</div>

					<aside class="notes">
						<ul>
							<li>Dispositivos utilizados, como funcionan</li>
						 	<li>Conjuntos de datos utilizados: el de eva y el del whoi</li>
					 </ul>
					</aside>
				</section>

				<section>
					<h3>Concepto de muestra</h3>
					<p>Una <span class="resaltar">muestra</span> es el conjunto de especímenes de plancton fotografiados por un dispositivo de captura en un <span class="resaltar">lugar y momento determinados</span></p>
					<img src="img/sampletoimages.png" style="width:100%" ></img>
					<figcaption>A partir de una muestra, después de un proceso automático de fotografiado y segmentación de las imágenes, obtenemos un conjunto de imágenes</figcaption>
				</section>



				<section>
					<h3>Ejemplo de la variabilidad de cada muestra (IEO)</h3>
					<img style="width:70%" src="img/distribucion.png"></img>
				</section>

				<section>
					<h3>Ejemplo de la variabilidad de cada muestra (WHOI)</h3>
					<p>Prevalencia de la clase Cerataulina</p>
					<img style="width:80%" src="img/samplevariation.png"></img>
				</section>

				<section>
					<h3>Dificultades que presentan ambos conjuntos</h3>
					<ul>
						<li>Grandes <spam class="resaltar">cambios en la distribución</spam> de muestra a muestra</li>
						<li><spam class="resaltar">Dificultad para reconocer</spam> cada una de las especies por parte de los expertos</li>
						<li>Diferentes <spam class="resaltar">subespecies</spam> en cada una de las categorías</li>
						<li><spam class="resaltar">Calidad</spam> de las imágenes</li>
					</ul>
				</section>

				<section>
					<h2>Fase 2</h2>
					<h3>Cálculo de características</h3>
				</section>

				<section>
					<h3>Enfoques utilizados</h3>
					<ul>
						<li>Características tradicionales (forma y textura)
						<li>Características computadas usando una CNN</li>
					</ul>
				</section>

				<section>
					<h3>Características tradicionales</h3>
					<p>Pertenecientes al campo de la <spam class="resaltar">visión artificial</spam>. Realizan una serie de cálculos matemáticos sobre los píxeles de la imagen.</p>
					<p style="text-align:left">Algunos ejemplos son los siguientes:</p>
					<ul>
						<li>Descriptores de forma (Fourier)</li>
						<li>Momentos invariantes (Hu)</li>
						<li>Atributos de textura (Haralick)</li>
					</ul>
				</section>

				<section>
					<h3>Características computadas por una CNN</h3>
					<!--<p>Una CNN es una <spam class="resaltar">red neuronal convolucional</spam></p>
					<p>Es una de las técnicas principales del <i>Deep Learning</i></p>-->
					<img src="img/deeplearning2.png" style="width:70%; padding: 10px" ></img>
				</section>

				<section>
					<h3>¿Como funciona una CNN?</h3>
					<p>La propia red es capaz de aprender a representar las imágenes</spam></p>
					<img src="img/cnn.png" style="background-color:white; padding: 10px" ></img>
				</section>

				<section>
					<h3>¿Por qué son interesantes las CNNs para nuestro problema?</h3>
					<ul>
					<li>Muy buenas para la clasificación de imágenes</p>
					<li>Posibilidad de utilizarlas para computar características de imágenes</p>
				  <li>Posibilidad de utilizar redes preentrenadas y adaptarlas a nuestro problema</p>
				</ul>

				</section>

				<section>
					<h3>Arquitecturas de CNNs</h3>
					<p>Una de las primeras CNN fue <span class="resaltar">AlexNet</span> en 2012 (8 capas)</p>
					<p>A partir de ahí han aparecido redes más prufundas como <span class="resaltar">VGG</span> (19 capas) o <span class="resaltar">Inception</span> (22 capas)</p>
					<p>Cuanto más profundas son las redes cuesta más entrenarlas y los resultados empiezan a empeorar</p>
				</section>

				<section>
					<h4>CNNs más profundas</h4>
					<p>Las redes <span class="resaltar">Resnet</span> resuelven el problema añadiendo un enlace entre capas</p>
					<img src="img/resnet.png" style="background-color:white; padding: 10px" ></img>
					<p>Con esta arquitectura las <span class="resaltar">Resnet</span> pueden superar las 100 capas</p>
				</section>

				<section>
					<h4>¿Por qué elegimos las Resnet?</h4>
					<p>Ganadoras del concurso ImageNet en 2015 con un error del 3.6%</p>
					<img src="img/imagenet.jpg" style="width:60%;background-color:white; padding: 10px" ></img>
				</section>

				<section>
					<h3>Transfer Learning</h3>
					<blockquote style="bacground-color:black">
						&ldquo;La aplicación de destrezas, conocimiento, y otras aptitudes que fueron aprendidas en una situación a otro problema de aprendizaje.&rdquo; (Perkins, 1992)
					</blockquote>
					<img src="img/transferlearning.jpg" style="background-color:white; padding: 10px" ></img>
				</section>

				<section>
					<h3>Fine Tuning</h3>
					<p><spam class="resaltar">Eliminamos la última capa</spam> de la red y la reemplazamos por una nueva adaptada a nuestro problema</p>
					<p><spam class="resaltar">Reentrenamos la red</spam> aplicando cambios muy pequeños presentándole imágenes de plancton</p>
				</section>

				<section>
					<h2>Fase 3</h2>
				  <h3>Algoritmos de cuantificación</h3>
				</section>

				<section>
					<h3>A Review on Quantification Learning</h3>
					<p>(ACM Computing Surveys, 2017)</p>
					<div class="container">

						<div class="col" style="margin:auto;margin-right:50px;flex:1 40%">
							<p>Introducción a la <span class="resaltar">cuantificación como problema con entidad propia</span> dentro del campo de aprendizaje automático y <span class="resaltar">revisión de los principales métodos</span> hasta la fecha</p>
						</div>
						<div class="col">
							<img style="width:100%" src="img/acmpage.png"/>
						</div>
					</div>
				</section>
				<section>
					<h3>¿Qué es cuantificar?</h3>
					<blockquote style="font-size:0.9em">Cuantificar consiste en estimar la distribución de las clases en un conjunto de test, usando un conjunto de entrenamiento que puede tener una distribución diferente <span class="resaltar">[Forman, 2008]</span></blockquote>
					<p>Dado un conjunto de datos $D=\{(x_1,y_1),...,(x_n,y_n)\}$<br>
					donde $x_i \in \mathcal{X}$ and $y_i \in \mathcal{Y}=\{c_1,...,c_l\}$</p>
					<p>El objetivo es aprender un modelo tal que: $\bar{h}:Sample \longrightarrow [0,1]^l$, donde cada elemento de este vector es la prevalencia de cada clase $\hat{p}_{j}$ en una muestra desconocida.

				</section>
				<section>
					<h3>¿Qué es cuantificar? (II)</h3>
					<img src="img/cuantificadordiagrama.png" style="width:80%;background-color:white; padding: 10px" ></img>

				</section>
				<section>
					<h3>Diferencias entre clasificación y cuantificación</h3>
					<p>Se puede observar que la <span class="resaltar">formulación</span> de ambos problemas es <span class="resaltar">totalmente diferente</span></p>
					<div style="width:70%;margin:auto">
						<div style="float:left">
							<p>Clasificación<br>$h:\mathcal{X}\longrightarrow \{c_1,...,c_l\}$</p>
						</div>
						<div style="float:right">
							<p>Cuantificación<br>$\bar{h}: Sample \longrightarrow [0,1]^l$</p>
						</div>
					</div>
				</section>

				<section>
					<h3>Cambios en la distribución</h3>
					<p>El aprendizaje automático supervisado está basado en que los datos son independientes y están distribuidos de manera idéntica (<spam class="resaltar">I.I.D. assumption</spam>)</p>
					<p>Esto supone que $P_{tr}(x,y)=P_{tst}(x,y)$</p>
					<p>En los problemas de cuantificación lo anterior claramente <span class="resaltar">no se cumple</span> ya que al menos $P_{tr}(y)\neq P_{tst}(y)$</p>
				</section>

				<section>
					<h3>Dataset Shift [Moreno et al. 2012]</h3>
					<p>$P(x, y) = P(y|x)P(x)$ en problemas $X \longrightarrow Y$<br>$P(x, y) = P(x|y)P(y)$ en problemas $Y \longrightarrow X$</p>
					<ul>
						<li><span class="resaltar">covariate shift</span>: $X → Y$, $P(x)$ cambia, $P(y|x)$ constante</li>
						<li style="background-color:#FFFFCC;"><span class="resaltar">prior probability shift</span>: $Y → X$ , $P(y)$ cambia, $P(x|y)$ constante</li>
						<li><span class="resaltar">concept shift</span>: $X → Y$, $P(y|x)$ cambia, $P(x)$ constante; $Y → X$ , $P(x|y)$ cambia, $P(y)$ constante</li>
					</ul>
					<aside class="notes">
						<ul>
							<li>Decir que <pan class="resaltar">la mayoría</span> de los algoritmos de cuantificación asumen que P(x|y es constante)</li>
					 </ul>
				</section>

				<section>
					<h3>La forma más sencilla de cuantificar</h3>
					<p>El método más sencillo para cuantificar es el método <span class="resaltar">Clasificar y Contar<span class="resaltar"> (CC)</p>
					<p>Este método <spam class="resaltar">no es óptimo</spam> y sus resultados pueden ser mejorados</p>
					<p><span class="resaltar">Un clasificador perfecto daría lugar a un cuantificador perfecto</span>, pero en la realidad nunca obtenemos un clasificador perfecto</p>
				</section>


				<section>
					<h3>¿Por qué el método CC no es óptimo? [Forman, 2008]</h3>
					<p>Podemos escribir la probabilidad de que un clasificador binario prediga un ejemplo como positivo de la siguiente manera:</p>
						<p style="text-align:left !important">$\begin{align}\hat{p}_{CC}=&P(h(x)=+1|y=+1)\cdot P(y=+1)+
							\\&P(h(x)=+1|y=-1)\cdot P(y=-1)\end{align}$
						<br><span class="resaltar">$\hat{p}_{CC}=tpr \cdot p + fpr \cdot (1-p)$</span></p>
						<p style="text-align:left !important">Si $tpr-fpr=1$ (clasificador perfecto, si $P(x|y)$ constante) $\implies \hat{p}_{CC}=p$</p>

				</section>

				<section>
					<h3>¿Por qué el método CC no es óptimo?</h3>
					<img src="img/CC.png" style="width:60%;background-color:white; padding: 10px" ></img>
				</section>

				<section>
					<h3>Algoritmos específicos para cuantificar</h3>
					<p>Los algoritmos utilizados en esta tesis han sido <spam class="resaltar">PCC</spam>, <spam class="resaltar">AC</spam>, <spam class="resaltar">PAC</spam> y <spam class="resaltar">HDy</spam></p>
					<aside class="notes">
						<ul>
							<li>Incluir los nombres completos de los algoritmos</li>
					 </ul>
				 </aside>
				</section>

				<section>
					<h3>Probabilistic CC [Bella et al. 2010]</h3>
					<p>PCC utiliza las salidas de un clasificador probabilistico para promediar la prevalencia de cada clase</p>
					<p>$\hat{p}^{PCC}=\frac{1}{|T|}\sum_{x \in T} P(y = +1 | x)$</p>
					<p>En realidad este algoritmo <span class="resaltar">adolece de los mismos defectos que CC</span></p>
				</section>

				<section>
					<h3>Adjusted Count [Forman, 2008] y Probabilistic Adjusted Count [Bella et al., 2010]</h3>
					<p>AC y PAC utilizan una <span class="resaltar">corrección</span> basada en el $tpr$ y $fpr$ del clasificador</p>
					<p>$\hat{p}^{AC}=\frac{\hat{p}^{CC}-fpr}{tpr-fpr}$</p>
					<p>El ajuste se obtiene al despejar la prevalencia real de la expresión que hemos visto antes:</p>
					<p>$\hat{p}_{CC}=tpr \cdot p + fpr \cdot (1-p)$</p>
					<p>Sería un <span class="resaltar">ajuste teóricamente perfecto</span> si la estimación de $tpr$ y $fpr$ fuesen correctas</p>
				</section>

				<section>
					<h3>HDy [González-Castro et al. 2013] (I)</h3>
					<p>Método basado en la comparación de distribuciones utilizando la <spam class="resaltar">distancia de Hellinger</spam></p>
					<img src="img/hdy.png" style="width:100%;background-color:white; padding: 10px" ></img>
					<aside class="notes">
						<ul>
							<li>Se utiliza un clasificador probabilístico por debajo</li>
							<li>Clasificamos el conjunto de entrenamiento</li>
							<li>Clasificamos el conjunto de test</li>
							<li>Pintamos un histograma para cada uno, simplemente donde van cayendo la prob devuelta por cada clasificador para cada ejemplo</li>
							<li>Vamos generando diferentes conjuntos variando p en el conjunto de entrenamiento y los comparamos con la distribución del conjunto de test usando HD</li>
					 </ul>
				 </aside>
				</section>

				<section>
					<h3>HDy [González-Castro et al. 2013] (II)</h3>
					<p>La distancia de Hellinger en su forma discreta se puede calcular de la siguiente manera:</p>
					<p>$HD(D',T)=\sqrt{\sum_{i=1}^{bins} \Big(\sqrt{ \frac{|D'_{i}|}{|D'|} } - \sqrt{ \frac{|T_{i}|}{|T|}}}\Big)^2$
					<p>Generamos conjuntos artificiales $D'$ variando $\hat{p}$ y hacemos una búsqueda lineal hasta encontrar el valor que minimiza la distancia anterior</p>
				</section>



				<section>
					<h3>Cuantificadores multiclase</h3>
					<div>
						<div style="float:left;width:50%">
					<p>Se utiliza un enfoque <span class="resaltar">one-vs-all</span> entrenando tantos cuantificadores binarios como clases tiene el problema</p>
					<p>El resultado final se <span class="resaltar">normaliza</span> para que las prevalencias obtenidas sumen uno</p>
				</div>
				<div style="float:right;width:50%">
						<img src="img/onevsall.png" style="width:80%;padding:10px;background-color:white" ></img>
					</div>
				</div>
				</section>

				<section>
					<h2>Fase 4</h2>
					<h3>Validación de resultados</h3>
				</section>


				<section>
					<h3>Validation methods for plankton image classification systems</h3>
					<p>(Limnology and Oceanography: Methods, 2016)</p>
					<div class="container">
						<div class="col" style="margin:auto;margin-right:50px;flex:1 40%">
							<p>Desarrollo de <span class="resaltar">métodos de validación apropiados</span> para problemas con grandes cambios en la distribución de sus muestras</p>
						</div>
						<div class="col">
							<img style="width:100%" src="img/lompage.png"/>
						</div>
					</div>
					<aside class="notes">
						<ul>
							<li>Artículo en revista de plancton</li>
							<li>Acostumbrados a validación cruzada tradicional por individuo</li>
							<li>Acostumbrados a crear muestras artificiales</li>
							<li>Obetivo: convencer a la comunidad del plancton de la importancia de usar la muestra como unidad mínima de validación</li>
					 </ul>
				 </aside>
				</section>
				<section>
					<h3>Estrategia de validación</h3>
					<p>La unidad mínima para los experimentos es la <spam class="resaltar">muestra</spam> y no el indivíduo</p>
					<p>Es importante considerar la muestra tal y como viene del dispositivo de captura, <span class="resaltar">sin ningún procesamiento manual posterior</span></p>
				</section>

				<section>
					<h3>Métodos de validación</h3>
					<ul>
						<li>Validación cruzada por muestra dejando una fuera (<spam class="resaltar">LOO por muestra</spam>) <i class="fa fa-arrow-right" style="font-size:24px"></i> cuando hay pocas muestras</li>
						<li>División del conjunto en entrenamiento y prueba (<spam class="resaltar">Hold-out</spam>) <i class="fa fa-arrow-right" style="font-size:24px"></i> cuando hay suficientes muestras</li>
					</ul>

					<aside class="notes">
						<ul>

					 </ul>
				 </aside>
				</section>

				<section>
					<h3>LOOCV</h3>
					<img src="img/loosample.png" style="width:50%;padding:10px;background-color:white" ></img>
				</section>

				<section>
					<h3>Comparación entre una CV por individuo y por muestra</h3>
					<figure>
						<img src="img/resultscvsample.png" style="width:80%;padding:10px;background-color:white" ></img>
						<figcaption><small>Resultados de acierto en porcentaje para el conjunto del IEO</small></figcaption>
					</figure>
					<aside class="notes">
						<ul>
							<aside class="notes">
								<ul>
									<li>$Acc$ sería el acierto promediando todos los ejemplos de todas las muestras (probabilidad de clasificar bien una imagen)</li>
									<li>$Acc_{sample}$ acierto calculado en cada muestra, promediandolo por el número de muestras</li>

							 </ul>
						 </aside>
					 </ul>
				 </aside>
				</section>

				<section>
					<h3>¿Por qué LOO por muestra obtiene peores resultados que una CV tradicional?</h3>
					<figure>
						<img src="img/reshellinger.png" style="width:80%;padding:10px;background-color:white" ></img>
					</figure>
					<aside class="notes">
						<ul>
							<li>HD entre entrenamiento y test para cada iteracción</li>
							<li>Decir que es una validación cruzada estratificada</li>
					 </ul>
				 </aside>
				</section>
				<section>
					<h3>Otras maneras de ver los resultados</h3>
					<figure>
						<img src="img/comparacionclases.png" style="width:100%;padding:10px;background-color:white" ></img>
					</figure>
					<aside class="notes">
						<ul>
							<li>Hay una muestra en ciliados que da cero. viendola vemos que los 142 ejemplos de esa clase pertenecen a una subespecie. Solo hay estos 142 ejemplos en todo el conjunto!</li>
					 </ul>
				 </aside>
				</section>

				<section>
					<h3>¿Por qué utilizar la muestra como unidad mínima?</h3>
					<ul>
						<li>Se añade una <spam class="resaltar">variabilidad real</spam> en los experimentos.</li>
						<li>Se obtiene una <spam class="resaltar">estimación más realista</spam> del rendimiento del modelo.</li>
						<li>Nos permite un <spam class="resaltar">análisis más detallado</spam> de los resultados y la posible detección de errores.</li>
					</ul>
				</section>



				<section>
					<h3>Automatic plankton quantification using deep features</h3>
					<p>(Journal of Plankton Research, 2019)</p>
					<div class="container">
						<div class="col" style="margin:auto;margin-right:50px;flex:1 40%">
							<p>Uso de <span class="resaltar">deep learning</span> y <span class="resaltar">transfer learning</span> para cuantificar muestras de plancton</p>
						</div>
						<div class="col">
							<img style="width:100%" src="img/jprpage.png"/>
						</div>
					</div>
				</section>

				<section>
					<h3>Hold-out por muestra</h3>
					<p>En este caso el conjunto de muestras era suficiente como para utilizar un <span class="resaltar">Hold-out por muestra</span> como estrategia de validación</p>
					<figure>
  					<img src="img/holdout.png" style="width:60%;padding:10px;background-color:white" ></img>
  					<figcaption><small>Muestras del conjunto WHOI-Plankton.</small></figcaption>
					</figure>
				</section>

				<section>
					<h3>Medidas de error</h3>
					<p>Las medidas de error utilizadas tienen que ser específicas para el problema de cuantificación</p>
				</section>

				<section>
					<h4>Error absoluto medio (MAE)</h3>
<p>
					$MAE(c_{j})=\frac{1}{m} \sum_{s=1}^{m} | p_{j,s} - \hat{p}_{j,s} |$</p>
					<p>Valor fácilmente interpretable en el rango [0,1]

				</section>

				<section>
					<h3>Error absoluto relativo medio (MRAE)</h3>
					<p>$MRAE(c_{j})=\frac{1}{m} \sum_{s=1}^{m} \frac{\epsilon+|p_{j,s} - \hat{p}_{j,s}|}{\epsilon + p_{j,s}}$</p>
				</section>

				<section>
					<h3>Resultados para el conjunto WHOI-Plankton</h3>
					<figure>
					<img src="img/resultsae.png" style="padding:10px; width:90%"</img>
					<figcaption>Tabla con todos los errores MAE para NF (características tradicionales) y Resnets de diferentes tamaños (reentrenadas y sin reentrenar*)</figcaption>
</figure>
				</section>
				<section>
					<h3>Resultados para el conjunto WHOI-Plankton (II)</h3>
					<figure>
					<img src="img/graphresults1.png" style="padding:10px; width:100%"</img>
					<figcaption>Comparación por clase entre CC-NF y AC-RN101</figcaption>
</figure>
				</section>
				<section>
					<h3>Resultados para el conjunto WHOI-Plankton (III)</h3>
					<figure>
					<img src="img/graphresults2.png" style="padding:10px; width:100%"</img>
					<figcaption>Comparación por clase entre CC-NF y AC-RN101</figcaption>
</figure>
				</section>

				<section>
						<h3>Conclusiones</h3>
						<ul>
							<li>Analizar el funcionamiento de los <span class="resaltar">métodos de cuantificación</span> en un problema real como es el plankton</li>
							<li>Definir una <span class="resaltar">estrategia de validación sólida</span> extrapolable a otros problemas de cuantificación</li>
							<li>Combinar los avances en el campo de la <span class="resaltar">visión artificial</span> (CNNs) con las técnicas de <span class="resaltar">cuantificación</span></li>
						</ul>
				</section>





				<section>
					<h3>Difusión y reproducibilidad de los resultados</h3>
					<p>Los resultados de esta tesis han sido publicados en <span class="resaltar">tres revistas indexadas</span> de reconocido prestigio</p>
					<p style="text-align:left">Con el fin de garantizar la <span class="resaltar">reproducibilidad de los resultados</span>:</p>
					<ul style="font-size:70%">
						<li>Se ha creado una cuenta de <a href="https://github.com/pglez82/IFCB_quantification">GitHub</a> con todo el código necesario para repetir los experimentos</li>
						<li>Todas las herramientas utilizadas para los experimentos son <span class="resaltar">Open Source</span></li>
					</ul>
					<aside class="notes">
						<ul>
							<li>Indicar además que todo ha sido hecho con software libre</li>
					 </ul>
				</section>

				<section>
					<h2>FIN</h2>
					<h4>Muchas gracias por la atención</h4>
				</section>


			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				history: true,

				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					//{ src: 'plugin/mathsvg/math.js', async: true },
					{ src: 'plugin/math/math.js', async: true },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
			Reveal.configure({ slideNumber: true })
		</script>
	</body>
</html>
